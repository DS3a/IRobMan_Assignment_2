{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "The following assignment is going to cover lectures 5, 6, 7 & 8.\n",
    "\n",
    "## Broad Topics are\n",
    "\n",
    "- Object Tracking\n",
    "- Multi-Sensor Fusion\n",
    "- Grasp Generation & Evalutaion\n",
    "- Force Control\n",
    "\n",
    "# Maximum Marks possible: [$60 = 30 + 20 + 10$]\n",
    "If individual marks for a subpart are not specified assume equal marks for all the subparts within that section.\n",
    "\n",
    "## How to Answer ?:\n",
    "For theoretical questions make a markdown cell below each question/question-subpart and write the answer there. (yes handwritten solutions are allowed too but you need to be careful while linking it)\n",
    "For coding questions write the answer at the designated position indicated by the question.\n",
    "\n",
    "## Submission:\n",
    "You have to submit the file assignment_2.ipynb with your answers into Moodle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Tracking a Ball [Full Marks: $30 = 20 + 10$]\n",
    "\n",
    "\n",
    "## Question1: Kalman Filter [Marks: $20$]\n",
    "\n",
    "### Background\n",
    "In this task, you will simulate the motion of a ball thrown in a vacuum and use a Kalman filter to track its trajectory. According to Newtonian physics, the motion of the ball in a constant gravitational field can be described by the following equations:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y &= \\frac{g}{2}t^2 + v_{y0} t + y_0 \\\\\n",
    "x &= v_{x0} t + x_0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ g $ : gravitational acceleration constant\n",
    "- $ t $ : time\n",
    "- $ v_{x0}, v_{y0} $ : initial velocity components\n",
    "- $ x_0, y_0 $ : initial position of the ball\n",
    "\n",
    "If the ball is thrown with an initial velocity $v$ at an angle $\\theta$ (above the horizontal), the initial velocity components can be computed as:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "v_{x0} &= v \\cos{\\theta} \\\\\n",
    "v_{y0} &= v \\sin{\\theta}\n",
    "\\end{aligned}\n",
    "$$\n",
    "Because we don't have real data we will start by writing a simulator for a ball. As always, we add a noise term independent of time so we can simulate noisy sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import radians, sin, cos\n",
    "from numpy.random import randn\n",
    "from filterpy.kalman import KalmanFilter\n",
    "\n",
    "def rk4(y, x, dx, f):\n",
    "    \"\"\"computes 4th order Runge-Kutta for dy/dx.\n",
    "    y is the initial value for y\n",
    "    x is the initial value for x\n",
    "    dx is the difference in x (e.g. the time step)\n",
    "    f is a callable function (y, x) that you supply to \n",
    "      compute dy/dx for the specified values.\n",
    "    \"\"\"\n",
    "    \n",
    "    k1 = dx * f(y, x)\n",
    "    k2 = dx * f(y + 0.5*k1, x + 0.5*dx)\n",
    "    k3 = dx * f(y + 0.5*k2, x + 0.5*dx)\n",
    "    k4 = dx * f(y + k3, x + dx)\n",
    "    \n",
    "    return y + (k1 + 2*k2 + 2*k3 + k4) / 6.\n",
    "\n",
    "def fx(x,t):\n",
    "    return fx.vel\n",
    "    \n",
    "def fy(y,t):\n",
    "    return fy.vel - 9.8*t\n",
    "\n",
    "\n",
    "class BallTrajectory2D(object):\n",
    "    def __init__(self, x0, y0, velocity, \n",
    "                 theta_deg=0., \n",
    "                 g=9.8, \n",
    "                 noise=[0.0, 0.0]):\n",
    "        self.x = x0\n",
    "        self.y = y0\n",
    "        self.t = 0        \n",
    "        theta = math.radians(theta_deg)\n",
    "        fx.vel = math.cos(theta) * velocity\n",
    "        fy.vel = math.sin(theta) * velocity        \n",
    "        self.g = g\n",
    "        self.noise = noise\n",
    "        \n",
    "        \n",
    "    def step(self, dt):\n",
    "        self.x = rk4(self.x, self.t, dt, fx)\n",
    "        self.y = rk4(self.y, self.t, dt, fy)\n",
    "        self.t += dt \n",
    "        return (self.x + randn()*self.noise[0], \n",
    "                self.y + randn()*self.noise[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to create a trajectory starting at (0, 15) with a velocity of 100 m/s and an angle of 60° we would write:\n",
    "\n",
    "```python\n",
    "traj = BallTrajectory2D(x0=0, y0=15, velocity=100, theta_deg=60)\n",
    "```\n",
    "    \n",
    "and then call `traj.step(t)` for each time step. Let's test this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ball_vacuum(noise):\n",
    "    y = 15\n",
    "    x = 0\n",
    "    ball = BallTrajectory2D(x0=x, y0=y, \n",
    "                            theta_deg=60., velocity=100., \n",
    "                            noise=noise)\n",
    "    t = 0\n",
    "    dt = 0.25\n",
    "    while y >= 0:\n",
    "        x, y = ball.step(dt)\n",
    "        t += dt\n",
    "        if y >= 0:\n",
    "            plt.scatter(x, y, color='r', marker='.', s=75, alpha=0.5)\n",
    "         \n",
    "    plt.axis('equal');\n",
    "    plt.show()\n",
    "    \n",
    "#test_ball_vacuum([0, 0]) # plot ideal ball position\n",
    "test_ball_vacuum([1, 1]) # plot with noise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the State Variables\n",
    "Given a ball moving in a vacuum, its motion is governed by the following discretized equations derived using Euler’s method with a time step $\\Delta t$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x_t &= x_{t-1} + v_{x(t-1)}\\Delta t \\\\\n",
    "v_{x t} &= v_{x(t-1)} \\\\\n",
    "y_t &= y_{t-1} + v_{y(t-1)}\\Delta t \\\\\n",
    "v_{y t} &= v_{y(t-1)} - g\\Delta t\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "These equations assume constant horizontal velocity $v_x$ and vertical acceleration due to gravity $g$ only. We wish to implement a Kalman filter to track the ball’s state over time. The Kalman filter’s state prediction equation is:\n",
    "\n",
    "$$\n",
    "\\mathbf{\\bar{x}} = \\mathbf{F}\\mathbf{x} + \\mathbf{B}\\mathbf{u}\n",
    "$$\n",
    "\n",
    "- $\\mathbf{F}$ represents the state transition matrix.\n",
    "- $\\mathbf{B}$ represents how control inputs affect the state.\n",
    "- $\\mathbf{u}$ is the control input vector, here corresponding to gravity.\n",
    "\n",
    "We define the state vector as:\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = \\begin{bmatrix} x & \\dot{x} & y & \\dot{y} \\end{bmatrix}^\\mathsf{T}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing the State Transition Function\n",
    "\n",
    "The state transition function is represented by the matrix $\\mathbf{F}$. Multiplying $\\mathbf{F}$ by the previous state $\\mathbf{x}$ yields the predicted state $\\bar{\\mathbf{x}}$:\n",
    "\n",
    "$$\n",
    "\\bar{\\mathbf{x}} = \\mathbf{F}\\mathbf{x}\n",
    "$$\n",
    "\n",
    "Given the state vector\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = \\begin{bmatrix} x & \\dot{x} & y & \\dot{y} \\end{bmatrix}^\\mathsf{T},\n",
    "$$\n",
    "\n",
    "the discretized equations of motion (neglecting gravity here since it will be included as a control input) are:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\bar{x} &= x + \\dot{x}\\Delta t \\\\\n",
    "\\bar{\\dot{x}} &= \\dot{x} \\\\\n",
    "\\bar{y} &= y + \\dot{y}\\Delta t \\\\\n",
    "\\bar{\\dot{y}} &= \\dot{y}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "In matrix form, this corresponds to:\n",
    "\n",
    "$$\n",
    "\\mathbf{F} = \\begin{bmatrix}\n",
    "1 & \\Delta t & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & \\Delta t \\\\\n",
    "0 & 0 & 0 & 1\n",
    "\\end{bmatrix}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing the Control Input Function\n",
    "\n",
    "To incorporate gravitational acceleration into the Kalman filter, we utilize the control input term $\\mathbf{Bu}$, where $\\mathbf{u}$ represents the control input (gravity) and $\\mathbf{B}$ represents how this input affects the state. The purpose is to account for the change in the state vector $\\bar{\\mathbf{x}}$ due to gravity between time steps.\n",
    "\n",
    "From the discretized equations:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x_t &= x_{t-1} + v_{x(t-1)} \\Delta t \\\\\n",
    "v_{x t} &= v_{x(t-1)} \\\\\n",
    "y_t &= y_{t-1} + v_{y(t-1)} \\Delta t \\\\\n",
    "v_{y t} &= v_{y(t-1)} - g \\Delta t\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "It follows that gravity affects only the vertical velocity component $\\dot{y}$. Therefore, we require:\n",
    "\n",
    "$$\n",
    "\\mathbf{B}\\mathbf{u} = \\begin{bmatrix}0 \\\\ 0 \\\\ 0 \\\\ -g \\Delta t \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "The exact structure of $\\mathbf{B}$ and $\\mathbf{u}$ is somewhat flexible, as long as their product yields the desired change in state. One suitable choice, adhering to the notion that $\\mathbf{u}$ should contain the control input itself (i.e., $-g$) and that $\\mathbf{B}$ should incorporate the time step, is:\n",
    "\n",
    "$$\n",
    "\\mathbf{B} = \\begin{bmatrix}0 \\\\ 0 \\\\ 0 \\\\ \\Delta t \\end{bmatrix}, \\quad\n",
    "\\mathbf{u} = \\begin{bmatrix}-g\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "This formulation clearly separates the control input ($-g$) from the time step ($\\Delta t$), ensuring that time remains a parameter of $\\mathbf{B}$, the control function, rather than being embedded directly into $\\mathbf{u}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design the Measurement Function\n",
    "\n",
    "The measurement function defines how we go from the state variables to the measurements using the equation $\\mathbf z = \\mathbf{Hx}$. We will assume that we have a sensor that provides us with the position of the ball in (x,y), but cannot measure velocities or accelerations. Therefore our function must be:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}z_x \\\\ z_y \\end{bmatrix}= \n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0\n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix}\n",
    "x \\\\\n",
    "\\dot x \\\\\n",
    "y \\\\\n",
    "\\dot y \\end{bmatrix}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\mathbf H = \\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design the Measurement Noise Matrix\n",
    "\n",
    "As with the robot, we will assume that the error is independent in $x$ and $y$. In this case we will start by assuming that the measurement errors in x and y are 0.5 meters squared. Hence,\n",
    "\n",
    "$$\\mathbf R = \\begin{bmatrix}0.5&0\\\\0&0.5\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design the Process Noise Matrix\n",
    "\n",
    "We are assuming a ball moving in a vacuum, so there should be no process noise. We have 4 state variables, so we need a $4{\\times}4$ covariance matrix:\n",
    "\n",
    "$$\\mathbf Q = \\begin{bmatrix}0&0&0&0\\\\0&0&0&0\\\\0&0&0&0\\\\0&0&0&0\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design the Initial Conditions\n",
    "\n",
    "We already performed this step when we tested the state transition function. Recall that we computed the initial velocity for $x$ and $y$ using trigonometry, and set the value of $\\mathbf x$ with:\n",
    "\n",
    "```python\n",
    "omega = radians(omega)\n",
    "vx = cos(omega) * v0\n",
    "vy = sin(omega) * v0\n",
    "\n",
    "f1.x = np.array([[x, vx, y, vy]]).T\n",
    "```\n",
    "    \n",
    "With all the steps done we are ready to implement our filter and test it. First, the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos, radians\n",
    "\n",
    "def ball_kf(x, y, omega, v0, dt, r=0.5, q=0.):\n",
    "\n",
    "    ########### TODO ##################\n",
    "    # Initialize Kalman filter: 4 states (x, vx, y, vy), 2 measurements (x, y), 1 control input (gravity)\n",
    "\n",
    "\n",
    "    # State transition matrix F\n",
    "    # States: x, vx, y, vy\n",
    "    # x   = x_previous + vx*dt\n",
    "    # vx  = vx_previous\n",
    "    # y   = y_previous + vy*dt\n",
    "    # vy  = vy_previous\n",
    "\n",
    "    \n",
    "\n",
    "    # Measurement function H\n",
    "    # We measure only position (x, y), no velocities\n",
    "\n",
    "    # Control input matrix B\n",
    "    # Only vy is affected by control input (gravity)\n",
    "    # B maps the control input (u = -g) to a change in vy:\n",
    "    # vy_new = vy_old + (-g)*dt, so we place dt in the vy row.\n",
    "\n",
    "\n",
    "    #####################################\n",
    "    omega = radians(omega)\n",
    "    vx = cos(omega) * v0\n",
    "    vy = sin(omega) * v0\n",
    "    kf.x = np.array([[x, vx, y, vy]]).T\n",
    "    return kf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will test the filter by generating measurements for the ball using the ball simulation class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_ball_vacuum(dt):\n",
    "    global kf\n",
    "    x, y = 0., 1.\n",
    "    theta = 35.  # launch angle\n",
    "    v0 = 80.\n",
    "    g = np.array([[-9.8]])  # gravitational constant\n",
    "    ball = BallTrajectory2D(x0=x, y0=y, theta_deg=theta, velocity=v0, \n",
    "                            noise=[.2, .2])\n",
    "    kf = ball_kf(x, y, theta, v0, dt)\n",
    "\n",
    "    t = 0\n",
    "    xs, ys = [], []\n",
    "    while kf.x[2] > 0:\n",
    "        ######################## TODO ############################\n",
    "        # Predict the next state given the control input (gravity)\n",
    "        # Obtain new noisy measurement from the simulated ball\n",
    "        # Update the Kalman filter with the new measurement\n",
    "        # Store the results\n",
    "        ##########################################################\n",
    "\n",
    "        ##########################################################\n",
    "    p2, = plt.plot(xs, ys, lw=2)\n",
    "    plt.legend([p2, p1], ['Kalman filter', 'Measurements'],\n",
    "               scatterpoints=1)\n",
    "    plt.show()\n",
    "track_ball_vacuum(dt=1./10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the Kalman filter reasonably tracks the ball. However, as already explained, this is a trivial example because we have no process noise. We can predict trajectories in a vacuum with arbitrary precision; using a Kalman filter in this example is a needless complication. A least squares curve fit would give identical results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking a Ball in Air"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem, we assume that we are tracking a ball travelling through the Earth's atmosphere. The path of the ball is influenced by wind, drag, and the rotation of the ball. We will assume that our sensor is a camera; code that we will not implement will perform some type of image processing to detect the position of the ball. This is typically called *blob detection* in computer vision. However, the image processing code is not perfect; in any given frame it is possible to either detect no blob or to detect spurious blobs that do not correspond to the ball. Finally, we will not assume that we know the starting position, angle, or rotation of the ball; the tracking code will have to initiate tracking based on the measurements that are provided. The main simplification that we are making here is a 2D world; we assume that the ball is always travelling orthogonal to the plane of the camera's sensor. We have to make that simplification at this point because we have not discussed how we might extract 3D information from a camera, which provides only 2D data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Air Drag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step is to implement the math for a ball moving through air. There are several treatments available. A robust solution takes into account issues such as ball roughness (which affects drag non-linearly depending on velocity), the Magnus effect (spin causes one side of the ball to have a higher velocity relative to the air vs the opposite side, so the coefficient of drag differs on opposite sides), the effect of lift, humidity, air density, and so on. I assume the reader is not interested in the details of ball physics, and so will restrict this treatment to the effect of air drag on a non-spinning baseball. I will use the math developed by Nicholas Giordano and Hisao Nakanishi in *Computational Physics*  [1997]. This treatment does not take all the factors into account. The most detailed treatment is by Alan Nathan on his website at http://baseball.physics.illinois.edu/index.html. I use his math in my work in computer vision, but I do not want to get distracted by a more complicated model.\n",
    "\n",
    "**Important**: Before I continue, let me point out that you will not have to understand this next piece of physics to proceed with the Kalman filter. My goal is to create a reasonably accurate behaviour of a baseball in the real world so that we can test how our Kalman filter performs with real-world behaviour. In real-world applications, it is usually impossible to completely model the physics of a real-world system, and we make do with a process model that incorporates large-scale behaviours. We then tune the measurement noise and process noise until the filter works well with our data. There is a real risk to this; it is easy to finely tune a Kalman filter so it works perfectly with your test data, but performs badly when presented with slightly different data. This is perhaps the hardest part of designing a Kalman filter, and why it gets referred to with terms such as 'black art'. \n",
    "\n",
    "I dislike books that implement things without explanation, so I will now develop the physics for a ball moving through air. Move on past the implementation of the simulation if you are not interested. \n",
    "\n",
    "A ball moving through air encounters wind resistance. This imparts a force on the wall, called *drag*, which alters the flight of the ball. In Giordano, this is denoted as\n",
    "\n",
    "$$F_{drag} = -B_2v^2$$\n",
    "\n",
    "where $B_2$ is a coefficient derived experimentally, and $v$ is the velocity of the object. $F_{drag}$ can be factored into $x$ and $y$ components with\n",
    "\n",
    "$$\\begin{aligned}\n",
    "F_{drag,x} &= -B_2v v_x\\\\\n",
    "F_{drag,y} &= -B_2v v_y\n",
    "\\end{aligned}$$\n",
    "\n",
    "If $m$ is the mass of the ball, we can use $F=ma$ to compute the acceleration as\n",
    "\n",
    "$$\\begin{aligned} \n",
    "a_x &= -\\frac{B_2}{m}v v_x\\\\\n",
    "a_y &= -\\frac{B_2}{m}v v_y\n",
    "\\end{aligned}$$\n",
    "\n",
    "Giordano provides the following function for $\\frac{B_2}{m}$, which takes air density, the cross-section of a baseball, and its roughness into account. Understand that this is an approximation based on wind tunnel tests and several simplifying assumptions. It is in SI units: velocity is in meters/sec and time is in seconds.\n",
    "\n",
    "$$\\frac{B_2}{m} = 0.0039 + \\frac{0.0058}{1+\\exp{[(v-35)/5]}}$$\n",
    "\n",
    "Starting with this Euler discretization of the ball path in a vacuum:\n",
    "$$\\begin{aligned}\n",
    "x &= v_x \\Delta t \\\\\n",
    "y &= v_y \\Delta t \\\\\n",
    "v_x &= v_x \\\\\n",
    "v_y &= v_y - 9.8 \\Delta t\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We can incorporate this force (acceleration) into our equations by incorporating $accel * \\Delta t$ into the velocity update equations. We should subtract this component because drag will reduce the velocity. The code to do this is quite straightforward, we just need to break out the force into $x$ and $y$ components. \n",
    "\n",
    "I will not belabour this issue further because computational physics is beyond the scope of this book. Recognize that a higher fidelity simulation would require incorporating things like altitude, temperature, ball spin, and several other factors. The aforementioned work by Alan Nathan covers this if you are interested. My intent here is to impart some real-world behaviour into our simulation to test how our simpler prediction model used by the Kalman filter reacts to this behaviour. Your process model will never exactly model what happens in the world, and a large factor in designing a good Kalman filter is carefully testing how it performs against real-world data. \n",
    "\n",
    "The code below computes the behaviour of a baseball in the air, at sea level, in the presence of wind. I plot the same initial hit with no wind, and then with a tail wind at 10 mph. Baseball statistics are universally done in US units, and we will follow suit here (http://en.wikipedia.org/wiki/United_States_customary_units). Note that the velocity of 110 mph is a typical exit speed for a baseball for a home run hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt, exp\n",
    "\n",
    "def mph_to_mps(x):\n",
    "    return x * .447\n",
    "\n",
    "def drag_force(velocity):\n",
    "    \"\"\" Returns the force on a baseball due to air drag at\n",
    "    the specified velocity. Units are SI\"\"\"\n",
    "\n",
    "    return velocity * (0.0039 + 0.0058 / \n",
    "            (1. + exp((velocity-35.)/5.)))\n",
    "\n",
    "v = mph_to_mps(110.)\n",
    "x, y = 0., 1.\n",
    "dt = .1\n",
    "theta = radians(35)\n",
    "\n",
    "def solve(x, y, vel, v_wind, launch_angle):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    v_x = vel*cos(launch_angle)\n",
    "    v_y = vel*sin(launch_angle)\n",
    "    while y >= 0:\n",
    "        # Euler equations for x and y\n",
    "        x += v_x*dt\n",
    "        y += v_y*dt\n",
    "\n",
    "        # force due to air drag    \n",
    "        velocity = sqrt((v_x-v_wind)**2 + v_y**2)    \n",
    "        F = drag_force(velocity)\n",
    "\n",
    "        # euler's equations for vx and vy\n",
    "        v_x = v_x - F*(v_x-v_wind)*dt\n",
    "        v_y = v_y - 9.8*dt - F*v_y*dt\n",
    "        \n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    \n",
    "    return xs, ys\n",
    "        \n",
    "x, y = solve(x=0, y=1, vel=v, v_wind=0, launch_angle=theta)\n",
    "p1 = plt.scatter(x, y, color='blue', label='no wind')\n",
    "wind = mph_to_mps(10)\n",
    "x, y = solve(x=0, y=1, vel=v, v_wind=wind, launch_angle=theta)\n",
    "p2 = plt.scatter(x, y, color='green', marker=\"v\", \n",
    "                 label='10mph wind')\n",
    "plt.legend(scatterpoints=1);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily see the difference between the trajectory in a vacuum and the air. I used the same initial velocity and launch angle in the ball in the vacuum section above. We computed that the ball in a vacuum would travel over 240 meters (nearly 800 ft). In the air, the distance is just over 120 meters or roughly 400 ft. 400ft is a realistic distance for a well-hit home run ball, so we can be confident that our simulation is reasonably accurate.\n",
    "\n",
    "Without further ado, we will create a ball simulation that uses the math above to create a more realistic ball trajectory. I will note that the nonlinear behaviour of drag means that there is no analytic solution to the ball position at any point in time, so we need to compute the position step-wise. I use Euler's method to propagate the solution; the use of a more accurate technique such as Runge-Kutta is left as an exercise for the reader. That modest complication is unnecessary for what we are doing because the accuracy difference between the techniques will be small for the time steps we will be using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseballPath:\n",
    "    def __init__(self, x0, y0, launch_angle_deg, velocity_ms, \n",
    "                 noise=(1.0, 1.0)): \n",
    "        \"\"\" Create 2D baseball path object  \n",
    "           (x = distance from start point in ground plane, \n",
    "            y=height above ground)\n",
    "        \n",
    "        x0,y0            initial position\n",
    "        launch_angle_deg angle ball is travelling respectively to \n",
    "                         ground plane\n",
    "        velocity_ms      speed of ball in meters/second\n",
    "        noise            amount of noise to add to each position\n",
    "                         in (x, y)\n",
    "        \"\"\"\n",
    "        \n",
    "        omega = radians(launch_angle_deg)\n",
    "        self.v_x = velocity_ms * cos(omega)\n",
    "        self.v_y = velocity_ms * sin(omega)\n",
    "\n",
    "        self.x = x0\n",
    "        self.y = y0\n",
    "        self.noise = noise\n",
    "\n",
    "\n",
    "    def drag_force(self, velocity):\n",
    "        \"\"\" Returns the force on a baseball due to air drag at\n",
    "        the specified velocity. Units are SI\n",
    "        \"\"\"\n",
    "        B_m = 0.0039 + 0.0058 / (1. + exp((velocity-35.)/5.))\n",
    "        return B_m * velocity\n",
    "\n",
    "\n",
    "    def update(self, dt, vel_wind=0.):\n",
    "        \"\"\" compute the ball position based on the specified time \n",
    "        step and wind velocity. Returns (x, y) position tuple.\n",
    "        \"\"\"\n",
    "\n",
    "        # Euler equations for x and y\n",
    "        self.x += self.v_x*dt\n",
    "        self.y += self.v_y*dt\n",
    "\n",
    "        # force due to air drag\n",
    "        v_x_wind = self.v_x - vel_wind\n",
    "        v = sqrt(v_x_wind**2 + self.v_y**2)\n",
    "        F = self.drag_force(v)\n",
    "\n",
    "        # Euler's equations for velocity\n",
    "        self.v_x = self.v_x - F*v_x_wind*dt\n",
    "        self.v_y = self.v_y - 9.81*dt - F*self.v_y*dt\n",
    "\n",
    "        return (self.x + randn()*self.noise[0], \n",
    "                self.y + randn()*self.noise[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test the Kalman filter against measurements created by this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = 0, 1.\n",
    "\n",
    "theta = 35. # launch angle\n",
    "v0 = 50.\n",
    "dt = 1/10.   # time step\n",
    "g = np.array([[-9.8]])\n",
    "\n",
    "plt.figure()\n",
    "ball = BaseballPath(x0=x, y0=y, launch_angle_deg=theta,\n",
    "                    velocity_ms=v0, noise=[.3,.3])\n",
    "f1 = ball_kf(x, y, theta, v0, dt, r=1.)\n",
    "f2 = ball_kf(x, y, theta, v0, dt, r=10.)\n",
    "t = 0\n",
    "xs, ys = [], []\n",
    "xs2, ys2 = [], []\n",
    "\n",
    "while f1.x[2] > 0:\n",
    "    t += dt\n",
    "    x, y = ball.update(dt)\n",
    "    z = np.array([[x, y]]).T\n",
    "\n",
    "    f1.update(z)\n",
    "    f2.update(z)\n",
    "    xs.append(f1.x[0])\n",
    "    ys.append(f1.x[2])\n",
    "    xs2.append(f2.x[0])\n",
    "    ys2.append(f2.x[2])    \n",
    "    f1.predict(u=g) \n",
    "    f2.predict(u=g)\n",
    "    \n",
    "    p1 = plt.scatter(x, y, color='r', marker='.', s=75, alpha=0.5)\n",
    "\n",
    "p2, = plt.plot(xs, ys, 'g', lw=2)\n",
    "p3, = plt.plot(xs2, ys2, 'b',lw=4)\n",
    "plt.legend([p1, p2, p3], \n",
    "           ['Measurements', 'Filter(R=0.5)', 'Filter(R=10)'],\n",
    "           loc='best', scatterpoints=1);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have plotted the output of two different Kalman filter settings. The measurements are depicted as green circles, a Kalman filter with R=0.5 as a thin green line, and a Kalman filter with R=10 as a thick blue line. These R values are chosen merely to show the effect of measurement noise on the output, they are not intended to imply a correct design.\n",
    "\n",
    "We can see that neither filter does very well. At first, both track the measurements well, but as time continues they both diverge. This happens because the state model for air drag is nonlinear and the Kalman filter assumes that it is linear. If you recall our discussion about nonlinearity in the g-h filter chapter we showed why a g-h filter will always lag behind the acceleration of the system. We see the same thing here - the acceleration is negative, so the Kalman filter consistently overshoots the ball position. There is no way for the filter to catch up so long as the acceleration continues, so the filter will continue to diverge.\n",
    "\n",
    "What can we do to improve this? The best approach is to perform the filtering with a nonlinear Kalman filter, and we will do this in subsequent chapters. However, there is also what I will call an 'engineering' solution to this problem. Our Kalman filter assumes that the ball is in a vacuum, and thus that there is no process noise. However, since the ball is in air the atmosphere imparts a force on the ball. We can think of this force as process noise. This is not a particularly rigorous thought; for one thing, this force is anything but Gaussian. Secondly, we can compute this force, so throwing our hands up and saying 'It's random' will not lead to an optimal solution. But let's see what happens if we follow this line of thought.\n",
    "\n",
    "The following code implements the same Kalman filter as before, but with a non-zero process noise. I plot two examples, one with `Q=.1`, and one with `Q=0.01`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ball_with_q(q, r=1., noise=0.3):\n",
    "    x, y = 0., 1.\n",
    "    theta = 35. # launch angle\n",
    "    v0 = 50.\n",
    "    dt = 1/10.   # time step\n",
    "    g = np.array([[-9.8]])\n",
    "\n",
    "    ball = BaseballPath(x0=x, \n",
    "                        y0=y, \n",
    "                        launch_angle_deg=theta, \n",
    "                        velocity_ms=v0, \n",
    "                        noise=[noise,noise])\n",
    "    f1 = ball_kf(x, y, theta, v0, dt, r=r, q=q)\n",
    "    t = 0\n",
    "    xs, ys = [], []\n",
    "\n",
    "    while f1.x[2] > 0:\n",
    "        t += dt\n",
    "        x, y = ball.update(dt)\n",
    "        z = np.array([[x, y]]).T\n",
    "\n",
    "        f1.update(z)\n",
    "        xs.append(f1.x[0])\n",
    "        ys.append(f1.x[2]) \n",
    "        f1.predict(u=g) \n",
    "\n",
    "        p1 = plt.scatter(x, y, c='r', marker='.', s=75, alpha=0.5)\n",
    "\n",
    "    p2, = plt.plot(xs, ys, lw=2, color='b')\n",
    "    plt.legend([p1, p2], ['Measurements', 'Kalman filter'])\n",
    "    plt.show()\n",
    "\n",
    "plot_ball_with_q(0.01)\n",
    "plot_ball_with_q(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second filter tracks the measurements fairly well. There appears to be a bit of lag, but very little.\n",
    "\n",
    "Is this a good technique? Usually not, but it depends. Here the nonlinearity of the force on the ball is fairly constant and regular. Assume we are trying to track an automobile - the accelerations will vary as the car changes speeds and turns. When we make the process noise higher than the actual noise in the system the filter will opt to weigh the measurements higher. If you don't have a lot of noise in your measurements this might work for you. However, consider this next plot where I have increased the noise in the measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ball_with_q(0.01, r=3, noise=3.)\n",
    "plot_ball_with_q(0.1, r=3, noise=3.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output is terrible. The filter has no choice but to give more weight to the measurements than the process (prediction step), but when the measurements are noisy the filter output will just track the noise. This inherent limitation of the linear Kalman filter is what led to the development of nonlinear versions of the filter.\n",
    "\n",
    "With that said, it is certainly possible to use the process noise to deal with small nonlinearities in your system. This is part of the 'black art' of Kalman filters. Our model of the sensors and the system are never perfect. Sensors are non-Gaussian and our process model is never perfect. You can mask some of this by setting the measurement errors and process errors higher than their theoretically correct values, but the trade-off is a non-optimal solution. Certainly, it is better to be non-optimal than to have your Kalman filter diverge. However, as we can see in the graphs above, it is easy for the output of the filter to be very bad. It is also very common to run many simulations and tests and to end up with a filter that performs very well under those conditions. Then, when you use the filter on real data the conditions are slightly different and the filter ends up performing terribly. \n",
    "\n",
    "For now we will set this problem aside, as we are misapplying the Kalman filter in this example. We will revisit this problem in subsequent chapters to see the effect of using various nonlinear techniques. In some domains, you will be able to get away with using a linear Kalman filter for a nonlinear problem, but usually you will have to use one or more of the techniques you will learn in the rest of this book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Particle Filter [Marks: $10$]\n",
    "\n",
    "Now following the lecture, we will implement a particle filter for the baseball trajectory tracking.\n",
    "Tune the parameters **motion_noise_std** and **measurement_noise** to get a good result. And explain why you chose the parameters you did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseballParticleFilter:\n",
    "    def __init__(self, num_particles, x0, y0, launch_angle_deg, velocity_ms, dt, \n",
    "                 measurement_noise=(1.0, 1.0),\n",
    "                 motion_noise_std=0.1):\n",
    "        \"\"\"Initialize particle filter for baseball trajectory tracking\n",
    "        \n",
    "        Args:\n",
    "            num_particles: Number of particles to use\n",
    "            x0, y0: Initial position\n",
    "            launch_angle_deg: Launch angle in degrees \n",
    "            velocity_ms: Initial velocity in m/s\n",
    "            dt: Time step\n",
    "            noise: Measurement noise in (x,y)\n",
    "        \"\"\"\n",
    "        self.num_particles = num_particles\n",
    "        self.dt = dt\n",
    "        self.measurement_noise = measurement_noise\n",
    "        self.motion_noise_std = motion_noise_std\n",
    "        \n",
    "        # Initialize particles at same starting state with small random noise\n",
    "        omega = radians(launch_angle_deg)\n",
    "        v_x = velocity_ms * cos(omega)\n",
    "        v_y = velocity_ms * sin(omega)\n",
    "        \n",
    "        # Each particle has state [x, vx, y, vy]\n",
    "        self.particles = np.zeros((num_particles, 4))\n",
    "        for i in range(num_particles):\n",
    "            self.particles[i] = [\n",
    "                x0 + randn()*0.1, \n",
    "                v_x + randn()*0.1,\n",
    "                y0 + randn()*0.1, \n",
    "                v_y + randn()*0.1\n",
    "            ]\n",
    "            \n",
    "        self.weights = np.ones(num_particles) / num_particles\n",
    "\n",
    "    def predict(self, g=-9.81):\n",
    "        \"\"\"Propagate particles through motion model with drag\"\"\"\n",
    "        for i in range(self.num_particles):\n",
    "            # Extract state\n",
    "            x, vx, y, vy = self.particles[i]\n",
    "            \n",
    "            # Update positions (Euler integration)\n",
    "            x += vx * self.dt\n",
    "            y += vy * self.dt\n",
    "            \n",
    "            vx = vx \n",
    "            vy = vy + g*self.dt\n",
    "            \n",
    "            # Add process noise\n",
    "            x += randn() * self.motion_noise_std\n",
    "            y += randn() * self.motion_noise_std\n",
    "            vx += randn() * self.motion_noise_std  \n",
    "            vy += randn() * self.motion_noise_std\n",
    "            \n",
    "            self.particles[i] = [x, vx, y, vy]\n",
    "\n",
    "    def update(self, measurement):\n",
    "        \"\"\"Update weights based on measurement likelihood\"\"\"\n",
    "        for i in range(self.num_particles):\n",
    "            # Calculate likelihood of measurement given particle position\n",
    "            x_diff = measurement[0] - self.particles[i,0]\n",
    "            y_diff = measurement[1] - self.particles[i,2]\n",
    "            \n",
    "            # Gaussian likelihood\n",
    "            likelihood = exp(-0.5 * (\n",
    "                (x_diff/self.measurement_noise[0])**2 + \n",
    "                (y_diff/self.measurement_noise[1])**2\n",
    "            ))\n",
    "            \n",
    "            self.weights[i] *= likelihood\n",
    "\n",
    "        # Normalize weights\n",
    "        self.weights += 1e-300  # Avoid division by zero\n",
    "        self.weights /= sum(self.weights)\n",
    "\n",
    "    def resample(self):\n",
    "        \"\"\"Resample particles based on weights\"\"\"\n",
    "        cumsum = np.cumsum(self.weights)\n",
    "        cumsum[-1] = 1.0\n",
    "        \n",
    "        # Generate random numbers\n",
    "        positions = np.random.random(self.num_particles)\n",
    "        \n",
    "        # Resample particles\n",
    "        new_particles = np.zeros((self.num_particles, 4))\n",
    "        for i in range(self.num_particles):\n",
    "            idx = np.searchsorted(cumsum, positions[i])\n",
    "            new_particles[i] = self.particles[idx]\n",
    "            \n",
    "        self.particles = new_particles\n",
    "        self.weights.fill(1.0 / self.num_particles)\n",
    "\n",
    "    def estimate(self):\n",
    "        \"\"\"Return weighted mean of particles as current estimate\"\"\"\n",
    "        mean = np.average(self.particles, weights=self.weights, axis=0)\n",
    "        return mean[0], mean[2]  # Return x,y position\n",
    "    \n",
    "\n",
    "# reinitialize the ball\n",
    "x, y = 0, 1.\n",
    "\n",
    "theta = 35. # launch angle\n",
    "v0 = 50.\n",
    "dt = 1/10.   # time step\n",
    "g = np.array([[-9.8]])\n",
    "\n",
    "ball = BaseballPath(x0=x, y0=y, launch_angle_deg=theta,\n",
    "                    velocity_ms=v0, noise=[.3,.3])\n",
    "\n",
    "# Initialize filter\n",
    "pf = BaseballParticleFilter(\n",
    "    num_particles=1000,\n",
    "    x0=0, y0=1,\n",
    "    launch_angle_deg=35,\n",
    "    velocity_ms=50,\n",
    "    dt=0.1,\n",
    "    #################TODO#####################\n",
    "    ## your parameters here\n",
    "    measurement_noise=[0.5, 0.5],\n",
    "    motion_noise_std=0.7\n",
    "    ## your parameters here\n",
    "    ## your explanation here\n",
    "    #########################################\n",
    ")\n",
    "\n",
    "# Track trajectory and plot\n",
    "xs, ys = [], []\n",
    "measurements_x, measurements_y = [], []\n",
    "\n",
    "while True:\n",
    "    # Get measurement from ball simulation\n",
    "    x, y = ball.update(dt)\n",
    "    measurements_x.append(x)\n",
    "    measurements_y.append(y)\n",
    "    \n",
    "    # Predict and update particle filter\n",
    "    pf.predict()\n",
    "    pf.update([x, y])\n",
    "    pf.resample()\n",
    "    \n",
    "    # Get estimate and store\n",
    "    x_est, y_est = pf.estimate()\n",
    "    xs.append(x_est)\n",
    "    ys.append(y_est)\n",
    "    \n",
    "    # Stop when ball hits ground\n",
    "    if y_est <= 0:\n",
    "        break\n",
    "\n",
    "# Final plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot particles\n",
    "plt.scatter(pf.particles[:,0], pf.particles[:,2], \n",
    "           color='gray', s=1, label='Particles')\n",
    "\n",
    "# Plot measurements\n",
    "plt.scatter(measurements_x, measurements_y, \n",
    "           color='r', alpha=0.5, label='Measurements')\n",
    "\n",
    "# Plot estimates\n",
    "plt.plot(xs, ys, 'b-', linewidth=2, label='Particle Filter Estimate')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.xlabel('X Position')\n",
    "plt.ylabel('Y Position')\n",
    "plt.title('Baseball Trajectory Tracking with Particle Filter')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the particle filter can track the trajectory of the baseball.\n",
    "\n",
    "However, due to the very wrong motion model, the particle filter is not able to track the trajectory very well.\n",
    "\n",
    "We are saying even though the position capture is quite well, but the trajectory is not smooth at all.\n",
    "\n",
    "Let's try to improve the motion model. and see if we can get a better result.\n",
    "\n",
    "You need to include the nonlinear drag force in the motion model. And tune the parameters to get a good result.\n",
    "\n",
    "Here we mean to get a smooth trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseballParticleFilter:\n",
    "    def __init__(self, num_particles, x0, y0, launch_angle_deg, velocity_ms, dt, \n",
    "                 measurement_noise=(1.0, 1.0),\n",
    "                 motion_noise_std=0.1):\n",
    "        \"\"\"Initialize particle filter for baseball trajectory tracking\n",
    "        \n",
    "        Args:\n",
    "            num_particles: Number of particles to use\n",
    "            x0, y0: Initial position\n",
    "            launch_angle_deg: Launch angle in degrees \n",
    "            velocity_ms: Initial velocity in m/s\n",
    "            dt: Time step\n",
    "            noise: Measurement noise in (x,y)\n",
    "        \"\"\"\n",
    "        self.num_particles = num_particles\n",
    "        self.dt = dt\n",
    "        self.measurement_noise = measurement_noise\n",
    "        self.motion_noise_std = motion_noise_std\n",
    "        \n",
    "        # Initialize particles at same starting state with small random noise\n",
    "        omega = radians(launch_angle_deg)\n",
    "        v_x = velocity_ms * cos(omega)\n",
    "        v_y = velocity_ms * sin(omega)\n",
    "        \n",
    "        # Each particle has state [x, vx, y, vy]\n",
    "        self.particles = np.zeros((num_particles, 4))\n",
    "        for i in range(num_particles):\n",
    "            self.particles[i] = [\n",
    "                x0 + randn()*0.1, \n",
    "                v_x + randn()*0.1,\n",
    "                y0 + randn()*0.1, \n",
    "                v_y + randn()*0.1\n",
    "            ]\n",
    "            \n",
    "        self.weights = np.ones(num_particles) / num_particles\n",
    "\n",
    "    def predict(self, g=-9.81):\n",
    "        \"\"\"Propagate particles through motion model with drag\"\"\"\n",
    "        for i in range(self.num_particles):\n",
    "            # Extract state\n",
    "            x, vx, y, vy = self.particles[i]\n",
    "            \n",
    "            # First update velocities\n",
    "            # Calculate velocity and drag force\n",
    "            \n",
    "            ########### TODO ##################\n",
    "\n",
    "            ###############################\n",
    "            \n",
    "            # Update velocities with drag and gravity\n",
    "            v_x_new = vx - drag_force * vx * self.dt  # Drag force in x direction\n",
    "            v_y_new = vy + g * self.dt - drag_force * vy * self.dt  # Gravity + drag force in y direction\n",
    "            \n",
    "            # Then update positions using new velocities\n",
    "            x_new = x + v_x_new * self.dt\n",
    "            y_new = y + v_y_new * self.dt\n",
    "            \n",
    "            # Add process noise\n",
    "            x_new += randn() * self.motion_noise_std\n",
    "            y_new += randn() * self.motion_noise_std\n",
    "            v_x_new += randn() * self.motion_noise_std\n",
    "            v_y_new += randn() * self.motion_noise_std\n",
    "            \n",
    "            self.particles[i] = [x_new, v_x_new, y_new, v_y_new]\n",
    "\n",
    "    def update(self, measurement):\n",
    "        \"\"\"Update weights based on measurement likelihood\"\"\"\n",
    "        for i in range(self.num_particles):\n",
    "            # Calculate likelihood of measurement given particle position\n",
    "            x_diff = measurement[0] - self.particles[i,0]\n",
    "            y_diff = measurement[1] - self.particles[i,2]\n",
    "            \n",
    "            # Gaussian likelihood\n",
    "            likelihood = exp(-0.5 * (\n",
    "                (x_diff/self.measurement_noise[0])**2 + \n",
    "                (y_diff/self.measurement_noise[1])**2\n",
    "            ))\n",
    "            \n",
    "            self.weights[i] *= likelihood\n",
    "\n",
    "        # Normalize weights\n",
    "        self.weights += 1e-300  # Avoid division by zero\n",
    "        self.weights /= sum(self.weights)\n",
    "\n",
    "    def resample(self):\n",
    "        \"\"\"Resample particles based on weights\"\"\"\n",
    "        cumsum = np.cumsum(self.weights)\n",
    "        cumsum[-1] = 1.0\n",
    "        \n",
    "        # Generate random numbers\n",
    "        positions = np.random.random(self.num_particles)\n",
    "        \n",
    "        # Resample particles\n",
    "        new_particles = np.zeros((self.num_particles, 4))\n",
    "        for i in range(self.num_particles):\n",
    "            idx = np.searchsorted(cumsum, positions[i])\n",
    "            new_particles[i] = self.particles[idx]\n",
    "            \n",
    "        self.particles = new_particles\n",
    "        self.weights.fill(1.0 / self.num_particles)\n",
    "\n",
    "    def estimate(self):\n",
    "        \"\"\"Return weighted mean of particles as current estimate\"\"\"\n",
    "        mean = np.average(self.particles, weights=self.weights, axis=0)\n",
    "        return mean[0], mean[2]  # Return x,y position\n",
    "    \n",
    "\n",
    "# reinitialize the ball\n",
    "x, y = 0, 1.\n",
    "\n",
    "theta = 35. # launch angle\n",
    "v0 = 50.\n",
    "dt = 1/10.   # time step\n",
    "g = np.array([[-9.8]])\n",
    "\n",
    "ball = BaseballPath(x0=x, y0=y, launch_angle_deg=theta,\n",
    "                    velocity_ms=v0, noise=[.3,.3])\n",
    "\n",
    "# Initialize filter\n",
    "pf = BaseballParticleFilter(\n",
    "    num_particles=1000,\n",
    "    x0=0, y0=1,\n",
    "    launch_angle_deg=35,\n",
    "    velocity_ms=50,\n",
    "    dt=0.1,\n",
    "    ## your parameters here\n",
    "    measurement_noise=[0.3, 0.3],\n",
    "    motion_noise_std=0.1\n",
    "    ## your parameters here\n",
    "    ## your explanation here\n",
    ")\n",
    "\n",
    "# Track trajectory and plot\n",
    "xs, ys = [], []\n",
    "measurements_x, measurements_y = [], []\n",
    "\n",
    "while True:\n",
    "    # Get measurement from ball simulation\n",
    "    x, y = ball.update(dt)\n",
    "    measurements_x.append(x)\n",
    "    measurements_y.append(y)\n",
    "    \n",
    "    # Predict and update particle filter\n",
    "    pf.predict()\n",
    "    pf.update([x, y])\n",
    "    pf.resample()\n",
    "    \n",
    "    # Get estimate and store\n",
    "    x_est, y_est = pf.estimate()\n",
    "    xs.append(x_est)\n",
    "    ys.append(y_est)\n",
    "    \n",
    "    # Stop when ball hits ground\n",
    "    if y_est <= 0:\n",
    "        break\n",
    "\n",
    "# Final plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot particles\n",
    "plt.scatter(pf.particles[:,0], pf.particles[:,2], \n",
    "           color='gray', s=1, label='Particles')\n",
    "\n",
    "# Plot measurements\n",
    "plt.scatter(measurements_x, measurements_y, \n",
    "           color='r', alpha=0.5, label='Measurements')\n",
    "\n",
    "# Plot estimates\n",
    "plt.plot(xs, ys, 'b-', linewidth=2, label='Particle Filter Estimate')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.xlabel('X Position')\n",
    "plt.ylabel('Y Position')\n",
    "plt.title('Baseball Trajectory Tracking with Particle Filter')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Grasping objects. [Full Marks: $20 = 5 + 7 + 2 + 6$]\n",
    "\n",
    "The goal of this task will be to implement a grasping pipeline for grasping an object in 3D space.\n",
    "\n",
    "We will not assume any obstacles for this case and focus our attention on grasp-sampling and grasp-scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "from typing import Tuple, Sequence, Optional\n",
    "\n",
    "from utils import visualize_3d_objs, create_grasp_mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start by loading object meshes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mesh_by_name(object_type: str,\n",
    "                     desired_vol: float = 0.000144) -> Tuple[o3d.geometry.TriangleMesh,\n",
    "                                                    np.ndarray, float]:\n",
    "    dataset_map = {\n",
    "        'armadillo': o3d.data.ArmadilloMesh,\n",
    "        'bunny': o3d.data.BunnyMesh,\n",
    "        'avocado': o3d.data.AvocadoModel\n",
    "    }\n",
    "\n",
    "    if object_type not in dataset_map:\n",
    "        raise ValueError(f\"Unsupported object type. Choose from: {list(dataset_map.keys())}\")\n",
    "\n",
    "    print(f\"Loading {object_type} mesh from Open3D dataset...\")\n",
    "    mesh = dataset_map[object_type]()\n",
    "\n",
    "    # Read and process mesh\n",
    "    loaded_mesh = o3d.io.read_triangle_mesh(mesh.path)\n",
    "    bbox = loaded_mesh.get_axis_aligned_bounding_box()\n",
    "    size = bbox.get_extent()\n",
    "    width, height, depth = size\n",
    "    print((f\"Mesh Dimensions Original:\\n\"\n",
    "           f\"- Width: {width:.2f}\\n\"\n",
    "           f\"- Height: {height:.2f}\\n\"\n",
    "           f\"- Depth: {depth:.2f}\"))\n",
    "    volume = width * height * depth\n",
    "    scale_factor = np.cbrt(desired_vol / volume)\n",
    "    loaded_mesh.scale(scale_factor, center=loaded_mesh.get_center())\n",
    "    loaded_mesh.compute_vertex_normals() # for fancy visualization\n",
    "    center = np.asarray(loaded_mesh.get_center())\n",
    "    bbox = loaded_mesh.get_axis_aligned_bounding_box()\n",
    "    size = bbox.get_extent()\n",
    "    width, height, depth = size\n",
    "    print((f\"Mesh Dimensions After Scaling:\\n\"\n",
    "           f\"- Width: {width:.2f}\\n\"\n",
    "           f\"- Height: {height:.2f}\\n\"\n",
    "           f\"- Depth: {depth:.2f}\"))\n",
    "\n",
    "    return loaded_mesh, center, scale_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visualize how this thing looks\n",
    "\n",
    "The $x, y, z$ axis will be rendered as red, green, and blue arrows respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "obj_name = 'avocado'\n",
    "mesh, center, scale = get_mesh_by_name(obj_name)\n",
    "\n",
    "coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "            size=0.1, origin=center)\n",
    "\n",
    "visualize_3d_objs([mesh, coordinate_frame])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make sure you close the visualizer before moving forward.**\n",
    "\n",
    "Now that we have the object and the coordinate frame, let's create a grasp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember everything here is in meters\n",
    "off_center = center + np.array([0, 0, 0.05])\n",
    "grasp = create_grasp_mesh(center_point=off_center)\n",
    "# grasp is multiple meshes, so make sure to unpack it\n",
    "visualize_3d_objs([mesh, coordinate_frame, *grasp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Complete the function to sample grasps [Marks: $5$]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will sample grasps around a target point in a sphere.\n",
    "\n",
    "Imagine the grasps getting sampled around a sphere where we can take any valid point inside the sphere.\n",
    "\n",
    "We can sample by leveraging polar coordinates $\\theta, \\phi, r$ for our sampling procedure.\n",
    "\n",
    "In the context of this question translation just means distance from center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_grasps(\n",
    "    center_point: np.ndarray,\n",
    "    num_grasps: int,\n",
    "    offset: float = 0.1,\n",
    ") -> Sequence[Tuple[np.ndarray, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Generates multiple random grasp poses around a given point cloud.\n",
    "\n",
    "    Args:\n",
    "        center: Center around which to sample grasps.\n",
    "        num_grasps: Number of random grasp poses to generate\n",
    "        offset: Maximum distance offset from the center (meters)\n",
    "\n",
    "    Returns:\n",
    "        list: List of rotations and Translations\n",
    "    \"\"\"\n",
    "\n",
    "    grasp_poses_list = []\n",
    "    for idx in range(num_grasps):\n",
    "        # Sample a grasp center and rotation of the grasp\n",
    "        # Sample a random vector in R3 for axis angle representation\n",
    "        # Return the rotation as rotation matrix + translation\n",
    "        # Translation implies translation from a center point\n",
    "        ############################TODO############################\n",
    "\n",
    "        ######################################################\n",
    "        assert R.shape == (3, 3)\n",
    "        assert grasp_center.shape == (3,)\n",
    "        grasp_poses_list.append((R, grasp_center))\n",
    "\n",
    "    return grasp_poses_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now using the sampled poses let's create a lot of grasp meshes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_grasp_lists = sample_grasps(center_point=center, num_grasps=100, offset=0.1)\n",
    "\n",
    "#######################TODO######################\n",
    "\n",
    "\n",
    "##################################################\n",
    "vis_meshes = [mesh, coordinate_frame]\n",
    "for grasp_mesh in all_grasp_meshes:\n",
    "    vis_meshes.extend(grasp_mesh)\n",
    "\n",
    "visualize_3d_objs(vis_meshes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Now we will check collision between two meshes using point clouds [Marks: 7]\n",
    "\n",
    "Use a KD tree to check if there is a collision between the two point-clouds.\n",
    "\n",
    "A collision is defined if there exists more than `num_collisions` set of two points one from each of the point-clouds which are less than or equal to `tolerance` away from each other.\n",
    "\n",
    "You can use the KD Tree from `o3d.geometry.KDTreeFlann`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to check if two meshes are equal\n",
    "def are_meshes_equal(mesh1: o3d.geometry.TriangleMesh,\n",
    "                     mesh2: o3d.geometry.TriangleMesh) -> bool:\n",
    "    # Compare vertices\n",
    "    if not np.array_equal(np.asarray(mesh1.vertices), np.asarray(mesh2.vertices)):\n",
    "        print(\"Vertex Problem\")\n",
    "        return False\n",
    "    \n",
    "    # Compare triangles\n",
    "    if not np.array_equal(np.asarray(mesh1.triangles), np.asarray(mesh2.triangles)):\n",
    "        print(\"Triangle Problem\")\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_grasp_collision(\n",
    "    grasp_meshes: Sequence[o3d.geometry.TriangleMesh],\n",
    "    object_mesh: o3d.geometry.TriangleMesh,\n",
    "    num_colisions: int = 10,\n",
    "    tolerance: float = 0.00001) -> bool:\n",
    "    \"\"\"\n",
    "    Checks for collisions between a gripper grasp pose and target object\n",
    "    using point cloud sampling.\n",
    "\n",
    "    Args:\n",
    "        grasp_meshes: List of mesh geometries representing the gripper components\n",
    "        object_mesh: Triangle mesh of the target object\n",
    "        num_collisions: Threshold on how many points to check\n",
    "        tolerance: Distance threshold for considering a collision (in meters)\n",
    "\n",
    "    Returns:\n",
    "        bool: True if collision detected between gripper and object, False otherwise\n",
    "    \"\"\"\n",
    "    # Combine gripper meshes\n",
    "    combined_gripper = o3d.geometry.TriangleMesh()\n",
    "    for mesh in grasp_meshes:\n",
    "        combined_gripper += mesh\n",
    "\n",
    "    # Sample points from both meshes\n",
    "    num_points = 5000 # Subsample both meshes to this many points\n",
    "    #######################TODO#######################\n",
    "\n",
    "    ##################################################\n",
    "    # Build KDTree for object points\n",
    "    is_collision = False\n",
    "    #######################TODO#######################\n",
    "\n",
    "\n",
    "    #######################TODO#######################\n",
    "\n",
    "    return is_collision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visualize all gripper poses which are not in collision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "vis_meshes = [mesh, coordinate_frame]\n",
    "for grasp_mesh in all_grasp_meshes:\n",
    "    first_finger = copy.copy(grasp_mesh[0])\n",
    "    if not check_grasp_collision(grasp_mesh, mesh):\n",
    "        vis_meshes.extend(grasp_mesh)\n",
    "    # to verify that the mesh is not modified\n",
    "    assert are_meshes_equal(first_finger, grasp_mesh[0])\n",
    "\n",
    "visualize_3d_objs(vis_meshes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You might still be seeing a lot of gripper positions which are in the way.**\n",
    "\n",
    "### Question 3: Let's create a filter which removes all grasps more than a certain distance away. [Marks: $2$]\n",
    "\n",
    "Add your code here in the following two cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grasp_dist_filter(center_grasp: np.ndarray,\n",
    "                      mesh_center: np.ndarray,\n",
    "                      tolerance: float = 0.05)->bool:\n",
    "    is_within_range = False\n",
    "    #######################TODO#######################\n",
    "\n",
    "    ##################################################\n",
    "    return is_within_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize all grasps here that are within range**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_meshes = [mesh, coordinate_frame]\n",
    "for pose, grasp_mesh in zip(sample_grasp_lists, all_grasp_meshes):\n",
    "    center_grasp = pose[1]\n",
    "    not_collision = (not check_grasp_collision(grasp_mesh, mesh))\n",
    "    in_range = grasp_dist_filter(center_grasp, center)\n",
    "    if (not_collision and in_range):\n",
    "        vis_meshes.extend(grasp_mesh)\n",
    "\n",
    "visualize_3d_objs(vis_meshes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you don't see any grasps here the criterion might be too strict. You can either increase the total number of sampled grasps or increase the `is_within_range`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Now let's find a naive way to score grasps. [Marks: 6]\n",
    "\n",
    "We will be using a simple idea. We will compute how much of the object is contained\n",
    "within the grippers.\n",
    "\n",
    "![Grasp Image](../grasp_image.png)\n",
    "\n",
    "To check containment we will construct a set of rays as follows and check how many of them are intersecting with the object in consideration. \n",
    "\n",
    "For this assignment, we don't do a full ray casting but instead use a KD Tree for checking collision between the rays and the object pcd. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_grasp_containment(\n",
    "    left_finger_center: np.ndarray,\n",
    "    right_finger_center: np.ndarray,\n",
    "    finger_length: float,\n",
    "    object_pcd: o3d.geometry.PointCloud,\n",
    "    num_rays: int,\n",
    "    rotation_matrix: np.ndarray, # rotation-mat\n",
    ") -> Tuple[bool, float]:\n",
    "    \"\"\"\n",
    "    Checks if any line between the gripper fingers intersects with the object mesh.\n",
    "\n",
    "    Args:\n",
    "        left_finger_center: Center of Left finger of grasp\n",
    "        right_finger_center: Center of Right finger of grasp\n",
    "        finger_length: Finger Length of the gripper.\n",
    "        object_pcd: Point Cloud of the target object\n",
    "        clearance_threshold: Minimum required clearance between object and gripper\n",
    "\n",
    "    Returns:\n",
    "        tuple[bool, float]: (intersection_exists, intersection_depth)\n",
    "        - intersection_exists: True if any line between fingers intersects object\n",
    "        - intersection_depth: Depth of deepest intersection point\n",
    "    \"\"\"\n",
    "\n",
    "    left_center = np.asarray(left_finger_center)\n",
    "    right_center = np.asarray(right_finger_center)\n",
    "\n",
    "    intersections = []\n",
    "    # Check for intersections between corresponding points\n",
    "    object_tree = o3d.geometry.KDTreeFlann(object_pcd)\n",
    "\n",
    "    #######################TODO#######################\n",
    "\n",
    "\n",
    "\n",
    "    ##################################################\n",
    "\n",
    "\n",
    "    return any(intersections), containment_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take `finger_lengh = 0.03`, `num_rays=50`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_meshes = [mesh, coordinate_frame]\n",
    "mesh_pcd = mesh.sample_points_uniformly(number_of_points=50000)\n",
    "for pose, grasp_mesh in zip(sample_grasp_lists, all_grasp_meshes):\n",
    "    not_collision = False\n",
    "    in_range = False\n",
    "    contained = False\n",
    "    contained_percentage = 0.0\n",
    "    left_finger, right_finger = grasp_mesh[0], grasp_mesh[1]\n",
    "    contained, ratio = check_grasp_containment(\n",
    "        left_finger_center=left_finger.get_center(),\n",
    "        right_finger_center=right_finger.get_center(),\n",
    "        finger_length=0.03,\n",
    "        object_pcd=mesh_pcd,\n",
    "        num_rays=50,\n",
    "        rotation_matrix=pose[0]\n",
    "    )\n",
    "    contained_percentage = ratio\n",
    "    center_grasp = pose[1]\n",
    "    not_collision = (not check_grasp_collision(grasp_mesh, mesh))\n",
    "    in_range = grasp_dist_filter(center_grasp, center)\n",
    "    if ((not_collision and in_range) and contained):\n",
    "        color = [1.0 - contained_percentage,\n",
    "                 contained_percentage, 0.0]\n",
    "        for g_mesh in grasp_mesh:\n",
    "            # to make results look more interpretable\n",
    "            g_mesh.compute_vertex_normals()\n",
    "            g_mesh.paint_uniform_color(color)\n",
    "        vis_meshes.extend(grasp_mesh)\n",
    "visualize_3d_objs(vis_meshes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that grasp candidates cover more for the object. You can play around with different settings and different objects too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Force Control [Full Marks: $10$]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have implemented a force control algorithm for the robot arm during the lecture.\n",
    "\n",
    "Now let's see how it works.\n",
    "\n",
    "and let's extend the static force control to hybrid motion force control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import all necessary libraries\n",
    "import pybullet as p\n",
    "import pybullet_data\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quintic_spline_interpolation(start_pos, end_pos, duration, num_points):\n",
    "    \"\"\"\n",
    "    Generates a quintic spline trajectory between start and end positions.\n",
    "    \n",
    "    Args:\n",
    "        start_pos: Starting joint positions\n",
    "        end_pos: Target joint positions\n",
    "        duration: Total duration of trajectory\n",
    "        num_points: Number of points to generate\n",
    "        \n",
    "    Returns:\n",
    "        positions, velocities, accelerations for the trajectory\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays\n",
    "    start_pos = np.array(start_pos)\n",
    "    end_pos = np.array(end_pos)\n",
    "    \n",
    "    t = np.linspace(0, duration, num_points)\n",
    "    t0, tf = 0, duration\n",
    "    a0 = start_pos\n",
    "    a1 = np.zeros_like(start_pos)\n",
    "    a2 = np.zeros_like(start_pos)\n",
    "    a3 = (10 * (end_pos - start_pos)) / (tf**3)\n",
    "    a4 = (-15 * (end_pos - start_pos)) / (tf**4)\n",
    "    a5 = (6 * (end_pos - start_pos)) / (tf**5)\n",
    "    \n",
    "    positions = np.array([a0 + a1*t_i + a2*t_i**2 + a3*t_i**3 + a4*t_i**4 + a5*t_i**5 for t_i in t])\n",
    "    velocities = np.array([a1 + 2*a2*t_i + 3*a3*t_i**2 + 4*a4*t_i**3 + 5*a5*t_i**4 for t_i in t])\n",
    "    accelerations = np.array([2*a2 + 6*a3*t_i + 12*a4*t_i**2 + 20*a5*t_i**3 for t_i in t])\n",
    "    \n",
    "    return positions, velocities, accelerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the physics engine\n",
    "physicsClient = p.connect(p.GUI)  # Change to non-GUI mode to exclude rendering effects\n",
    "p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "p.setGravity(0, 0, -9.81)\n",
    "p.setRealTimeSimulation(0)  # Ensure real-time simulation is off\n",
    "\n",
    "# Load ground and robot\n",
    "planeId = p.loadURDF(\"plane.urdf\")\n",
    "robotId = p.loadURDF(\"franka_panda/panda.urdf\", [0, 0, 0], useFixedBase=True)\n",
    "\n",
    "# Add a cube\n",
    "cubeStartPos = [1.3, 0, 0.5]  # x=1.3m, y=0, z=0.5\n",
    "cubeStartOrientation = p.getQuaternionFromEuler([0, 0, 0])\n",
    "boxId = p.loadURDF(\"cube.urdf\", cubeStartPos, cubeStartOrientation)\n",
    "p.changeDynamics(boxId, -1, lateralFriction=0.01)\n",
    "\n",
    "# Set the mass of the cube\n",
    "heavy_mass = 10000.0  # Very large mass\n",
    "p.changeDynamics(boxId, -1, mass=heavy_mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get joint information\n",
    "num_joints = p.getNumJoints(robotId)\n",
    "for i in range(12):\n",
    "    print(p.getJointInfo(robotId, i))\n",
    "joint_indices = [i for i in range(num_joints) if p.getJointInfo(robotId, i)[2] != p.JOINT_FIXED]\n",
    "joint_indices = joint_indices[:7]  # Control only the main joints\n",
    "\n",
    "# Set initial joint angles\n",
    "init_joint_positions = [0, -0.785, 0, -2.356, 0, 1.571, 0.785]\n",
    "for i, pos in enumerate(init_joint_positions):\n",
    "    p.resetJointState(robotId, joint_indices[i], pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable motors for torque control\n",
    "p.setRealTimeSimulation(False)\n",
    "p.setJointMotorControlArray(\n",
    "    robotId,\n",
    "    joint_indices,\n",
    "    p.VELOCITY_CONTROL,\n",
    "    forces=[0] * len(joint_indices)\n",
    ")\n",
    "for link_idx in range(num_joints+1):\n",
    "    p.changeDynamics(robotId, link_idx, linearDamping=0.0, angularDamping=0.0, jointDamping=0.0)\n",
    "    p.changeDynamics(robotId, link_idx, maxJointVelocity=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup target position and orientation\n",
    "dof = 9\n",
    "cube_pos = cubeStartPos  \n",
    "cube_size = 1.0  \n",
    "target_pos = [cube_pos[0] - cube_size/2, cube_pos[1], cube_pos[2]]  # Center of the nearest face\n",
    "target_orn = [0.7071, 0, 0.7071, 0]  # Specified quaternion\n",
    "\n",
    "# Initialize control variables\n",
    "debug_text_id = None\n",
    "last_force_error = 0  # Differential term for force control\n",
    "force_error_integral = 0  # Integral term for force control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set camera position and angle\n",
    "camera_distance = 1.8\n",
    "camera_yaw = 0\n",
    "camera_pitch = -30\n",
    "camera_target_position = [0.7, 0, 0.5]\n",
    "p.resetDebugVisualizerCamera(camera_distance, camera_yaw, camera_pitch, camera_target_position)\n",
    "\n",
    "# Get end effector index and calculate IK\n",
    "end_effector = 10\n",
    "joint_poses = p.calculateInverseKinematics(\n",
    "    robotId,\n",
    "    11,\n",
    "    target_pos,\n",
    "    target_orn,\n",
    "    maxNumIterations=200,\n",
    "    residualThreshold=1e-5\n",
    ")\n",
    "target_joint_poses = joint_poses[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate trajectory\n",
    "duration = 2.0\n",
    "num_points = int(duration * 240)\n",
    "current_joint_positions = [state[0] for state in p.getJointStates(robotId, joint_indices)]\n",
    "positions, velocities, accelerations = quintic_spline_interpolation(\n",
    "    current_joint_positions, \n",
    "    target_joint_poses, \n",
    "    duration, \n",
    "    num_points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper function to get the quaternion difference for orientation control\n",
    "def quaternion_difference(q1, q2):\n",
    "    \"\"\"Compute the quaternion difference q_diff = q2 * conjugate(q1).\"\"\"\n",
    "    q1_conjugate = p.invertTransform([0, 0, 0], q1)[1]  # Conjugate of q1\n",
    "    q_diff = p.multiplyTransforms([0, 0, 0], q2, [0, 0, 0], q1_conjugate)[1]\n",
    "    return q_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: [Marks: $10$]\n",
    "The only thing we need to do is, when the force control is enabled, change the position control to a Jacobian transpose task space controller. Please fill out the code below.\n",
    "\n",
    "$$\\tau_{motion} = J^T[k_p(x_{target}-x)]$$\n",
    "\n",
    "So when the force control is enabled, we could still do this null space motion control. \n",
    "\n",
    "**Angular jacobian should multiply with the angular velocity not quaternion, please be careful!**\n",
    "Use quaternion_difference and p.getEulerFromQuaternion to get the angular velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main simulation loop\n",
    "simulation_time = 0\n",
    "simulation_duration = 10\n",
    "dt = 1./240.\n",
    "i = 0\n",
    "force_control_enabled = False\n",
    "position_tolerance = 0.05\n",
    "\n",
    "# Start recording video\n",
    "log_id = p.startStateLogging(p.STATE_LOGGING_VIDEO_MP4, \"simulation.mp4\")\n",
    "\n",
    "while simulation_time < simulation_duration:\n",
    "    # Get desired trajectory point\n",
    "    if i < num_points:\n",
    "        desired_positions = positions[i]\n",
    "        desired_velocities = velocities[i]\n",
    "        desired_accelerations = accelerations[i]\n",
    "        i += 1\n",
    "    else:\n",
    "        desired_positions = positions[-1]\n",
    "        desired_velocities = velocities[-1]\n",
    "        desired_accelerations = accelerations[-1]\n",
    "    \n",
    "    # Get current joint states\n",
    "    joint_states = p.getJointStates(robotId, joint_indices)\n",
    "    current_joint_positions = [state[0] for state in joint_states]\n",
    "    current_joint_velocities = [state[1] for state in joint_states]\n",
    "    \n",
    "    # Check if force control should be enabled\n",
    "    if not force_control_enabled:\n",
    "        position_errors = [abs(desired - current) for desired, current in zip(target_joint_poses, current_joint_positions)]\n",
    "        if all(error < position_tolerance for error in position_errors):\n",
    "            force_control_enabled = True\n",
    "            \n",
    "    # Calculate Jacobian\n",
    "    zero_vec = [0.0] * len(joint_indices)\n",
    "    jac_t, jac_r = p.calculateJacobian(\n",
    "        robotId, \n",
    "        end_effector,\n",
    "        [0, 0, 0],\n",
    "        current_joint_positions + [0.0, 0.0],\n",
    "        zero_vec + [0.0, 0.0],\n",
    "        zero_vec + [0.0, 0.0]\n",
    "    )\n",
    "    jac_t = np.array(jac_t)[:, :7]\n",
    "    jac_r = np.array(jac_r)[:, :7]\n",
    "    \n",
    "    # Get contact force\n",
    "    current_force = 0\n",
    "    contact_points = p.getContactPoints(robotId, boxId, linkIndexA=10)\n",
    "    if contact_points:\n",
    "        for contact in contact_points:\n",
    "            normal_force = contact[9]\n",
    "            current_force += normal_force\n",
    "    \n",
    "    # Force control\n",
    "    if force_control_enabled:\n",
    "        desired_force = 10.0\n",
    "        force_error = desired_force - current_force\n",
    "        force_error_d = force_error - last_force_error\n",
    "        force_error_integral += force_error\n",
    "        last_force_error = force_error\n",
    "        \n",
    "        kp_force = 0.5\n",
    "        ki_force = 1.\n",
    "        kd_force = 0.25\n",
    "        \n",
    "        force_control = np.array([\n",
    "            kp_force * force_error + ki_force * force_error_integral + kd_force * force_error_d,\n",
    "            0.0,\n",
    "            0.0\n",
    "        ])\n",
    "        force_torques = np.dot(jac_t.T, force_control)\n",
    "    else:\n",
    "        force_torques = np.zeros(7)\n",
    "    \n",
    "    # Position control\n",
    "    if force_control_enabled:\n",
    "        kp_pos = 10.0\n",
    "        kp_ang = 0.1\n",
    "        new_target_pos = target_pos + np.array([0.0, 0.0, 0.05]) # move the target position up by 5cm\n",
    "        endeffector_states = p.getLinkState(robotId, 11)\n",
    "        endeffector_pos = np.array(endeffector_states[0])\n",
    "        endeffector_ori = np.array(endeffector_states[1])\n",
    "        \n",
    "        #######################TODO#######################\n",
    "        # compute the position difference\n",
    "\n",
    "        # compute the quaternion difference\n",
    "\n",
    "        # compute the angular velocity, hint: use p.getEulerFromQuaternion\n",
    "\n",
    "        # compute the position + orientation torques\n",
    "\n",
    "        ###################################################\n",
    "    else:\n",
    "        kp_pos = 1.0\n",
    "        kd_pos = 0.5\n",
    "        position_errors = [desired - current for desired, current in zip(desired_positions, current_joint_positions)]\n",
    "        velocity_errors = [desired - current for desired, current in zip(desired_velocities, current_joint_velocities)]\n",
    "        position_torque = [kp_pos * pos_err + kd_pos * vel_err for pos_err, vel_err in zip(position_errors, velocity_errors)]\n",
    "    \n",
    "    # Calculate gravity compensation\n",
    "    gravity_comp_torques = p.calculateInverseDynamics(\n",
    "        robotId,\n",
    "        current_joint_positions + [0., 0.],\n",
    "        current_joint_velocities + [0., 0.],\n",
    "        desired_accelerations.tolist() + [0., 0.]\n",
    "    )\n",
    "    \n",
    "    # Combine all control terms\n",
    "    control_torques = [\n",
    "        pos_torque + ft + grav\n",
    "        for ft, pos_torque, grav in zip(force_torques, position_torque, gravity_comp_torques[:7])\n",
    "    ]\n",
    "    \n",
    "    # Apply control\n",
    "    p.setJointMotorControlArray(\n",
    "        robotId,\n",
    "        joint_indices,\n",
    "        p.TORQUE_CONTROL,\n",
    "        forces=control_torques\n",
    "    )\n",
    "    \n",
    "    # Update debug text\n",
    "    if force_control_enabled:\n",
    "        debug_text = f\"Contact Force: {current_force:.2f} N, Error: {force_error:.2f} N\"\n",
    "    else:\n",
    "        debug_text = f\"Contact Force: {current_force:.2f} N, Force Control: False\"\n",
    "    if debug_text_id is not None:\n",
    "        p.removeUserDebugItem(debug_text_id)\n",
    "    debug_text_id = p.addUserDebugText(\n",
    "        debug_text,\n",
    "        [0, 0, 1],\n",
    "        [1, 0, 0],\n",
    "        textSize=1.5,\n",
    "        lifeTime=2.\n",
    "    )\n",
    "    \n",
    "    # Step simulation\n",
    "    p.stepSimulation()\n",
    "    time.sleep(dt)\n",
    "    simulation_time += dt\n",
    "\n",
    "# Stop recording\n",
    "p.stopStateLogging(log_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.disconnect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the robot arm moving upwards while pushing the cube with controlled force.\n",
    "\n",
    "It is called hybrid motion force control because we are using both position control and force control at the same time.\n",
    "\n",
    "However, it is not always applicable to all tasks. During real-world applications, we need to design the motion and make it robust to different tasks. You can concatenate small steps to enable hybrid motion force control for long-horizon tasks. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "assignment2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
